# Exploding Kittens DQN - Proyecto Final

## ğŸ“ Estructura del Proyecto

```
PRFINAL/
â”œâ”€â”€ v1/                          # VersiÃ³n Simple (Original)
â”‚   â”œâ”€â”€ exploding_env.py         # Entorno con 5 tipos de cartas
â”‚   â”œâ”€â”€ dqn_training.py          # DQN clÃ¡sico (2 capas, 128 neuronas)
â”‚   â”œâ”€â”€ play_pygame.py           # UI bÃ¡sica
â”‚   â”œâ”€â”€ play_ascii.py            # Modo terminal
â”‚   â”œâ”€â”€ dqn_exploding_kittens.pth # Modelo entrenado V1
â”‚   â””â”€â”€ README.md                # DocumentaciÃ³n V1
â”‚
â”œâ”€â”€ v2/                          # VersiÃ³n Extendida (Mejorada)
    â”œâ”€â”€ exploding_env.py         # Entorno con 8 tipos de cartas + heurÃ­stica mejorada
    â”œâ”€â”€ dqn_training.py          # Double DQN (3 capas, 256â†’256â†’128)
    â”œâ”€â”€ play_pygame.py           # UI completa con nuevas cartas
    â”œâ”€â”€ play_ascii.py            # Modo terminal extendido
    â””â”€â”€ README.md                # DocumentaciÃ³n V2

```

## ğŸ¯ Versiones

### V1 - Simple (Estable)
**Para:** Aprendizaje bÃ¡sico, experimentaciÃ³n rÃ¡pida
- âœ… 5 tipos de cartas (Bomb, Defuse, Skip, Attack, Safe)
- âœ… DQN clÃ¡sico simple
- âœ… HeurÃ­stica bÃ¡sica
- âœ… Entrenamiento rÃ¡pido (800 episodios)
- âœ… UI limpia y funcional
- âš¡ **Listo para jugar**: Modelo pre-entrenado incluido

```bash
cd v1
python play_pygame.py  # Â¡Juega inmediatamente!
```

### V2 - Extended (Avanzada)
**Para:** InvestigaciÃ³n, mejores resultados, gameplay complejo
- âœ… 8 tipos de cartas (+See Future, Draw from Bottom, Shuffle)
- âœ… Double DQN con arquitectura profunda
- âœ… HeurÃ­stica inteligente multi-criterio
- âœ… Entrenamiento extenso (2000 episodios)
- âœ… UI completa con todas las mecÃ¡nicas
- ğŸ“ **Mejor para aprender**: ImplementaciÃ³n avanzada

```bash
cd v2
python dqn_training.py  # Entrenar primero
python play_pygame.py   # Jugar con modelo V2
```

## ğŸš€ Quick Start

### OpciÃ³n 1: Jugar V1 (Inmediato)
```bash
cd v1
python play_pygame.py
```

### OpciÃ³n 2: Entrenar y Jugar V2 (Recomendado)
```bash
cd v2
python dqn_training.py    # ~20-30 minutos en CPU
python play_pygame.py
```

### OpciÃ³n 3: Modo Terminal
```bash
cd v1  # o v2
python play_ascii.py
```

## ğŸ“Š ComparaciÃ³n de Versiones

| Feature | V1 | V2 |
|---------|----|----|
| **Cartas** | 5 tipos bÃ¡sicos | 8 tipos (3 nuevas) |
| **Espacio de acciones** | 6 | 9 |
| **Red Neuronal** | 128â†’128â†’6 | 256â†’256â†’128â†’9 |
| **Algoritmo** | DQN clÃ¡sico | Double DQN + Dropout |
| **HeurÃ­stica oponente** | Simple reactiva | Multi-criterio inteligente |
| **Entrenamiento** | 800 episodios | 2000 episodios |
| **Learning rate** | 1e-3 | 5e-4 |
| **Batch size** | 64 | 128 |
| **Win rate vs simple** | ~55% | ~70% |
| **Win rate vs mejorado** | ~40% | ~55% |
| **Tiempo entrenamiento** | ~10 min | ~30 min |
| **Modelo pre-entrenado** | âœ… Incluido | âŒ Entrenar primero |

## ğŸ® CÃ³mo Jugar

### Controles Pygame:
- **Click** en botones de acciÃ³n
- **DRAW**: Robar carta(s) requeridas
- **SKIP**: Reducir draws en 1
- **ATTACK**: Oponente debe robar 2
- **SEE FUTURE** (V2): Ver top 3 cartas
- **DRAW BOTTOM** (V2): Robar del fondo
- **SHUFFLE** (V2): Mezclar deck
- **LOG**: Toggle game log
- **RESTART**: Nuevo juego (game over)

### Reglas BÃ¡sicas:
1. Cada turno debes robar cartas hasta completar tu `pending_draws`
2. **Skip** reduce `pending_draws` en 1 (no a 0)
3. **Attack** hace que oponente deba robar 2 (tÃº no robas)
4. **Bomb** te mata si no tienes **Defuse**
5. Con **Defuse** eliges dÃ³nde reinsertar la bomba

### Estrategias:
- ğŸ¯ Usa **Skip** cuando hay muchas bombas
- âš”ï¸ Usa **Attack** cuando tengas ventaja de cartas
- ğŸ”® (V2) Usa **See Future** antes de decidir
- â¬‡ï¸ (V2) Usa **Draw from Bottom** si top es peligroso
- ğŸ”„ (V2) Usa **Shuffle** despuÃ©s de Defuse del oponente

## ğŸ“š DocumentaciÃ³n

### Para Usuarios:
- `v1/README.md` - GuÃ­a V1
- `v2/README.md` - GuÃ­a V2 (mÃ¡s detallada)

### Para Desarrolladores:
- `RESPUESTAS_TEORICAS.md` - AnÃ¡lisis tÃ©cnico completo:
  - Â¿CÃ³mo funciona el deck? (Cola vs probabilidades)
  - AnÃ¡lisis de heurÃ­sticas
  - Mejoras del agente explicadas
  - ImplementaciÃ³n de nuevas cartas
  - Roadmap de mejoras futuras

## ğŸ”§ Requisitos

```bash
pip install pygame torch numpy matplotlib
```

O usar el virtualenv existente:
```bash
source venv/bin/activate  # macOS/Linux
```

## ğŸ“ Preguntas Frecuentes

### Â¿CuÃ¡l versiÃ³n debo usar?
- **V1**: Si quieres jugar rÃ¡pido o aprender lo bÃ¡sico
- **V2**: Si quieres el mejor agente y todas las features

### Â¿Por quÃ© V2 no tiene modelo pre-entrenado?
V2 tiene 9 acciones (vs 6 en V1), asÃ­ que necesita un modelo diferente. EntrÃ©nalo una vez con `python dqn_training.py`.

### Â¿Puedo usar el modelo V1 en V2?
No, las dimensiones son incompatibles. V1 tiene `action_dim=6` y V2 tiene `action_dim=9`.

### Â¿El deck es aleatorio cada turno?
No, el deck se mezcla UNA vez al inicio. Es una cola determinÃ­stica. Ver `RESPUESTAS_TEORICAS.md` para detalles.

### Â¿CÃ³mo mejorar el agente?
Ver secciÃ³n "Mejoras Futuras" en `v2/README.md` y `RESPUESTAS_TEORICAS.md`.

## ğŸ› Troubleshooting

### Error: "dqn_exploding_kittens_v2.pth not found"
```bash
cd v2
python dqn_training.py  # Entrena primero
```

### Error: "No module named 'exploding_env'"
```bash
# AsegÃºrate de estar en el directorio correcto
cd v1  # o v2
python play_pygame.py
```

### Agente juega mal
- V1: Modelo pre-entrenado incluido, deberÃ­a funcionar
- V2: Entrena por completo (2000 episodios)
- Verifica que el win rate sea >50% durante entrenamiento

## ğŸš€ PrÃ³ximos Pasos

1. **Juega V1** para entender las mecÃ¡nicas bÃ¡sicas
2. **Lee** `RESPUESTAS_TEORICAS.md` para entender el diseÃ±o
3. **Entrena V2** para ver las mejoras en acciÃ³n
4. **Experimenta** con hiperparÃ¡metros en V2
5. **Implementa** mejoras sugeridas (Prioritized Replay, Dueling DQN, etc.)

## ğŸ“ˆ Resultados Esperados

### V1 (Simple):
- Training: ~55% win rate vs heurÃ­stica simple
- Evaluation: ~55% win rate

### V2 (Mejorada):
- Training: ~60% win rate vs heurÃ­stica mejorada
- Evaluation: ~55-60% win rate
- Mejor comportamiento estratÃ©gico

## ğŸ‘¥ Contribuciones

Ideas para extender el proyecto:
- [ ] PPO / A3C implementation
- [ ] Multi-player (3-4 jugadores)
- [ ] MÃ¡s cartas del juego real
- [ ] Tournament mode
- [ ] AnÃ¡lisis de estrategias
- [ ] VisualizaciÃ³n de Q-values
- [ ] Self-play training

## ğŸ“ Licencia

Proyecto educativo - Reinforcement Learning Final Project

---

**Â¡Feliz aprendizaje y que exploten los gatitos! ğŸ±ğŸ’£**
