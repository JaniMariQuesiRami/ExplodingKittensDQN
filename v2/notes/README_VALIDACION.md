# ğŸ“Š Sistema de ValidaciÃ³n y Logging - V2

## ğŸ¯ Â¿QuÃ© se implementÃ³?

### **1. HeurÃ­stica de Entrenamiento V2**

#### **Arquitectura de Red Neuronal**
```
Entrada (state_dim) 
    â†“
Linear(256) + ReLU + Dropout(0.2)
    â†“
Linear(256) + ReLU + Dropout(0.2)
    â†“
Linear(128) + ReLU
    â†“
Linear(9 acciones)
```

#### **TÃ©cnicas de OptimizaciÃ³n**
| TÃ©cnica | Valor/Estado | DescripciÃ³n |
|---------|--------------|-------------|
| **Double DQN** | âœ… Activado | Reduce sobreestimaciÃ³n de Q-values |
| **Gradient Clipping** | max_norm=10.0 | Previene gradientes explosivos |
| **Target Network** | Update cada 100 eps | Mayor estabilidad (antes 50) |
| **Epsilon Decay** | Exponencial (0.9965) | ExploraciÃ³n mÃ¡s suave |
| **Early Stopping** | Patience=10 checkpoints | Guarda mejor modelo |
| **Replay Buffer** | 100,000 experiencias | Memoria de largo plazo |

#### **HiperparÃ¡metros**
```python
batch_size = 128              # â†‘ de 64 (mÃ¡s estable)
lr = 5e-4                     # â†“ de 1e-3 (menos agresivo)
epsilon_end = 0.01            # â†“ de 0.05 (mÃ¡s explotaciÃ³n)
gamma = 0.99                  # Factor de descuento
hidden_dim = 256              # â†‘ de 128 (mÃ¡s capacidad)
```

---

## ğŸ“ˆ Sistema de ValidaciÃ³n con Logging

### **Archivos Generados**

#### **1. CSVs de ValidaciÃ³n**
Se generan 2 archivos CSV por entrenamiento:

```csv
# validation_dqn_YYYYMMDD_HHMMSS.csv
game_id,turns,total_reward,won,actions_sequence
1,15,8.5,1,"0,1,2,0,6,8,0,1,..."
2,23,-2.1,0,"0,0,1,2,0,..."
...
```

```csv
# validation_random_YYYYMMDD_HHMMSS.csv
game_id,turns,total_reward,won,actions_sequence
1,28,-5.2,0,"0,2,0,1,0,..."
...
```

#### **2. GrÃ¡ficas de Entrenamiento**
`training_curves_v2.png`: 2 grÃ¡ficas lado a lado
- **Izquierda**: Recompensa media (ventana mÃ³vil 50 eps)
- **Derecha**: Win rate aproximado (ventana 50 eps)

#### **3. GrÃ¡ficas de ValidaciÃ³n**
`validation_analysis_YYYYMMDD_HHMMSS.png`: 4 grÃ¡ficas
- **Top-Left**: ComparaciÃ³n Win Rate (DQN vs Random)
- **Top-Right**: Histograma de turnos por juego
- **Bottom-Left**: DistribuciÃ³n de rewards
- **Bottom-Right**: % de uso de cada acciÃ³n (DQN)

---

## ğŸš€ CÃ³mo Usar

### **1. Entrenar con ValidaciÃ³n**
```bash
cd v2
python dqn_training.py
```

**Salida esperada:**
```
Usando dispositivo: mps
Ep 50/2000 | R_media_50=2.340 | WinRate_50=0.720 | eps=0.862
Ep 100/2000 | R_media_50=4.125 | WinRate_50=0.840 | eps=0.743
  âœ… Nuevo mejor modelo! WinRate: 0.840
...
ğŸ›‘ Early Stopping activado!
   Mejor WinRate: 0.960 en episodio 800
   Modelo restaurado al episodio 800

============================================================
ğŸ§ª FASE DE VALIDACIÃ“N
============================================================

ğŸ¤– Evaluando DQN Agent (400 juegos)...
ğŸ“ Log guardado en: validation_dqn_20241110_143022.csv

============================================================
ğŸ“Š RESUMEN DE VALIDACIÃ“N - DQN Agent
============================================================
Juegos totales: 400
Win Rate: 96.00% (384/400)
Turnos promedio: 12.45 Â± 3.21
Reward promedio: 9.23 Â± 2.15

AcciÃ³n          Total      %         
-----------------------------------
Draw            1245       28.50%
Skip            892        20.41%
Attack          654        14.96%
SeeFuture       789        18.05%
DrawBottom      423        9.68%
Shuffle         365        8.35%
...

ğŸ² Evaluando Random Agent (400 juegos)...
...
```

### **2. Analizar CSVs**
```bash
# Analizar un solo CSV
python analyze_validation.py validation_dqn_20241110_143022.csv

# Comparar dos CSVs (DQN vs Random)
python analyze_validation.py validation_dqn_*.csv validation_random_*.csv
```

**Ejemplo de salida:**
```
======================================================================
ğŸ“Š ANÃLISIS DE VALIDACIÃ“N: validation_dqn_20241110_143022.csv
======================================================================

ğŸ® MÃ‰TRICAS GENERALES:
  Total de juegos: 400
  Victorias: 384 (96.00%)
  Derrotas: 16

ğŸ“ˆ ESTADÃSTICAS DE TURNOS:
  Promedio: 12.45 Â± 3.21
  Mediana: 12
  Rango: [6, 24]

ğŸ’° ESTADÃSTICAS DE REWARD:
  Promedio: 9.23 Â± 2.15
  Mediana: 9.50
  Rango: [-3.20, 15.80]

ğŸ¯ DISTRIBUCIÃ“N DE ACCIONES:
  AcciÃ³n          Conteo     %          â–ˆ                   
  -------------------------------------------------------
  Draw            1245       28.50%     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  Skip            892        20.41%     â–ˆâ–ˆâ–ˆâ–ˆ
  Attack          654        14.96%     â–ˆâ–ˆ
  SeeFuture       789        18.05%     â–ˆâ–ˆâ–ˆ
  DrawBottom      423        9.68%      â–ˆ
  Shuffle         365        8.35%      â–ˆ

ğŸ† TOP 5 JUEGOS MÃS LARGOS:
  1. Game #127: 24 turnos, reward=12.30 âœ… WIN
  2. Game #89: 23 turnos, reward=11.80 âœ… WIN
  ...

âš¡ TOP 5 JUEGOS MÃS CORTOS:
  1. Game #234: 6 turnos, reward=-2.10 âŒ LOSS
  2. Game #45: 7 turnos, reward=8.50 âœ… WIN
  ...

ğŸ’ EJEMPLO DE SECUENCIA DE ACCIONES (Game #1):
  Draw â†’ Skip â†’ SeeFuture â†’ Draw â†’ Shuffle â†’ Draw â†’ Skip â†’ Attack...
```

---

## ğŸ” InterpretaciÃ³n de MÃ©tricas

### **Acciones (0-8)**
| ID | Nombre | DescripciÃ³n |
|----|--------|-------------|
| 0 | Draw | Robar carta del deck |
| 1 | Skip | Saltar turno (evita robar) |
| 2 | Attack | Termina turno, oponente roba 2 |
| 3-5 | Defuse1-3 | Desactivar bomba (3 slots) |
| 6 | SeeFuture | Ver 3 cartas del deck |
| 7 | DrawBottom | Robar del fondo del deck |
| 8 | Shuffle | Barajar el deck |

### **Win Rate Esperado**
- **Random Agent**: ~35-45%
- **DQN V2 (entrenado)**: ~92-96%
- **Meta**: >85% consistente

### **Turnos Promedio**
- **Random**: ~18-25 turnos (juega ineficientemente)
- **DQN V2**: ~10-15 turnos (estrategia eficiente)

### **Uso de Acciones Ã“ptimo (DQN)**
- **Draw**: ~25-30% (principal acciÃ³n)
- **Skip**: ~15-25% (evita bombas)
- **SeeFuture**: ~15-20% (planificaciÃ³n)
- **Attack**: ~10-15% (presiÃ³n al oponente)
- **Shuffle**: ~5-10% (reorganizar deck peligroso)

---

## ğŸ“ Estructura de Archivos

```
v2/
â”œâ”€â”€ dqn_training.py                    # â† Script principal de entrenamiento
â”œâ”€â”€ analyze_validation.py              # â† AnÃ¡lisis de CSVs
â”œâ”€â”€ training_curves_v2.png             # â† GrÃ¡ficas de entrenamiento
â”œâ”€â”€ validation_analysis_*.png          # â† GrÃ¡ficas de validaciÃ³n
â”œâ”€â”€ validation_dqn_*.csv               # â† Log de juegos DQN
â”œâ”€â”€ validation_random_*.csv            # â† Log de juegos Random
â”œâ”€â”€ dqn_exploding_kittens_v2.pth       # â† Modelo final
â””â”€â”€ best_model_checkpoint.pth          # â† Checkpoint del mejor modelo
```

---

## ğŸ§ª Diferencias: Entrenamiento vs ValidaciÃ³n

### **ENTRENAMIENTO** (Durante `train_dqn()`)
- **Objetivo**: Aprender polÃ­tica Ã³ptima
- **Epsilon**: Decae de 1.0 â†’ 0.01 (exploraciÃ³n â†’ explotaciÃ³n)
- **Replay Buffer**: Se llena con experiencias
- **Actualizaciones**: Gradientes, target network, early stopping
- **MÃ©tricas**: Reward medio, win rate aproximado (ventana 50 eps)
- **GrÃ¡ficas**: Curvas de aprendizaje durante entrenamiento

### **VALIDACIÃ“N** (DespuÃ©s de entrenar)
- **Objetivo**: Evaluar rendimiento real del modelo entrenado
- **Epsilon**: 0 (sin exploraciÃ³n, solo explotaciÃ³n)
- **Sin aprendizaje**: No se actualizan pesos
- **MÃ©tricas detalladas**: 
  - Win rate exacto (400 juegos)
  - DistribuciÃ³n de turnos
  - DistribuciÃ³n de rewards
  - AnÃ¡lisis de acciones tomadas
  - CSV con cada juego individual
- **GrÃ¡ficas**: Histogramas, comparaciones, anÃ¡lisis de comportamiento

---

## ğŸ’¡ Tips para InterpretaciÃ³n

### **Si Win Rate < 85%**
- âœ… Entrenar mÃ¡s episodios (aumentar `num_episodes`)
- âœ… Ajustar `epsilon_decay_rate` (mÃ¡s exploraciÃ³n)
- âœ… Revisar arquitectura (aumentar `hidden_dim`)

### **Si Win Rate > 95% pero turnos muy largos**
- âš ï¸ Posible sobreajuste a estrategia defensiva
- Revisar funciÃ³n de reward (penalizar turnos largos)

### **Si usa mucho Draw y poco SeeFuture**
- âš ï¸ No estÃ¡ usando informaciÃ³n disponible
- Reward de SeeFuture podrÃ­a ser muy bajo

### **ComparaciÃ³n DQN vs Random**
- DQN deberÃ­a tener:
  - âœ… Win rate +50-60% mayor
  - âœ… Turnos promedio -30% menor
  - âœ… Reward promedio significativamente mayor
  - âœ… Mayor uso de Skip/SeeFuture/Shuffle

---

## ğŸ“ Preguntas Frecuentes

**Q: Â¿Por quÃ© hay 2 grÃ¡ficas separadas (training y validation)?**  
A: Training muestra el proceso de aprendizaje (con ruido). Validation mide el rendimiento real sin exploraciÃ³n.

**Q: Â¿QuÃ© significa "actions_sequence" en el CSV?**  
A: La secuencia completa de acciones del juego. Ejemplo: `"0,1,6,0,2"` = Draw, Skip, SeeFuture, Draw, Attack.

**Q: Â¿Puedo comparar CSVs de diferentes entrenamientos?**  
A: SÃ­! Usa `analyze_validation.py archivo1.csv archivo2.csv` para comparar.

**Q: Â¿CÃ³mo sÃ© si el early stopping funcionÃ³ bien?**  
A: Si el modelo restaurado tiene win rate similar al pico de entrenamiento (Â±2%).

---

**Autor**: Sistema de Entrenamiento DQN V2  
**Fecha**: Noviembre 2024  
**VersiÃ³n**: 2.0 (Con validaciÃ³n exhaustiva)
